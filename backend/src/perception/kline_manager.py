#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Kçº¿æ•°æ®ç®¡ç†å™¨

å®ç°å¤šå±‚ç¼“å­˜ç­–ç•¥çš„Kçº¿æ•°æ®è·å–å’Œç®¡ç†:
1. å†…å­˜ç¼“å­˜ï¼ˆæœ€å¿«ï¼Œæ•°æ®æœ€æ–°ï¼‰
2. Redisç¼“å­˜ï¼ˆæ¬¡å¿«ï¼Œè¿‘æœŸæ•°æ®ï¼‰
3. PostgreSQLæ•°æ®åº“ï¼ˆå†å²æ•°æ®ï¼‰
4. APIå®æ—¶è·å–ï¼ˆå…œåº•æ–¹æ¡ˆï¼‰
"""

import asyncio
import logging
import time
from datetime import datetime, timedelta, timezone
from decimal import Decimal
from typing import Any, Dict, List, Optional

from src.perception.kline_config import (
    KLINE_CONFIGS,
    DEFAULT_FETCH_STRATEGY,
    DataFetchStrategy,
    TimeframeConfig,
)


class KlineDataManager:
    """
    Kçº¿æ•°æ®ç®¡ç†å™¨

    èŒè´£:
    1. å¤šå±‚ç¼“å­˜æ•°æ®è·å–ï¼ˆå†…å­˜ â†’ Redis â†’ DB â†’ APIï¼‰
    2. å¤šå‘¨æœŸKçº¿é‡‡é›†è°ƒåº¦
    3. è¿‡æœŸæ•°æ®æ¸…ç†
    4. æ•°æ®ä¸€è‡´æ€§ä¿è¯
    """

    def __init__(
        self,
        symbols: List[str],
        market_collector: Any,
        short_term_memory: Any,
        dao: Optional[Any] = None,
        db_manager: Optional[Any] = None,
        strategy: DataFetchStrategy = DEFAULT_FETCH_STRATEGY,
        logger: Optional[logging.Logger] = None,
    ):
        """
        åˆå§‹åŒ–Kçº¿æ•°æ®ç®¡ç†å™¨

        Args:
            symbols: äº¤æ˜“å¯¹åˆ—è¡¨
            market_collector: å¸‚åœºæ•°æ®é‡‡é›†å™¨ï¼ˆAPIï¼‰
            short_term_memory: RedisçŸ­æœŸå†…å­˜
            dao: æ•°æ®åº“DAO (å·²åºŸå¼ƒï¼Œä½¿ç”¨db_manager)
            db_manager: æ•°æ®åº“ç®¡ç†å™¨ï¼ˆç”¨äºåˆ›å»ºç‹¬ç«‹sessionï¼‰
            strategy: æ•°æ®è·å–ç­–ç•¥
            logger: æ—¥å¿—è®°å½•å™¨
        """
        self.symbols = symbols
        self.market_collector = market_collector
        self.short_term_memory = short_term_memory
        self.dao = dao  # ä¿ç•™ç”¨äºå‘åå…¼å®¹
        self.db_manager = db_manager
        self.strategy = strategy
        self.logger = logger or logging.getLogger(__name__)

        # ä¸‰å±‚ç¼“å­˜
        self._memory_cache: Dict[str, Dict[str, Any]] = {}  # {cache_key: {data, timestamp}}
        self._last_collection: Dict[str, float] = {}  # {task_key: timestamp}

        # è¿è¡Œæ§åˆ¶
        self.running = False
        self._collection_tasks: List[asyncio.Task] = []

    def _get_cache_key(self, symbol: str, timeframe: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        return f"kline:{symbol}:{timeframe}"

    def _get_task_key(self, symbol: str, timeframe: str) -> str:
        """ç”Ÿæˆä»»åŠ¡é”®"""
        return f"{symbol}:{timeframe}"

    async def start(self) -> None:
        """å¯åŠ¨å¤šå‘¨æœŸKçº¿é‡‡é›†ä»»åŠ¡"""
        if self.running:
            self.logger.warning("Kçº¿é‡‡é›†ä»»åŠ¡å·²åœ¨è¿è¡Œ")
            return

        self.running = True
        self.logger.info("ğŸš€ å¯åŠ¨å¤šå‘¨æœŸKçº¿é‡‡é›†ä»»åŠ¡")

        # ä¸ºæ¯ä¸ªäº¤æ˜“å¯¹å’Œæ—¶é—´å‘¨æœŸåˆ›å»ºé‡‡é›†ä»»åŠ¡
        for symbol in self.symbols:
            for timeframe, config in KLINE_CONFIGS.items():
                task = asyncio.create_task(
                    self._collection_loop(symbol, timeframe, config)
                )
                self._collection_tasks.append(task)

                self.logger.info(
                    f"  å¯åŠ¨ {symbol} {timeframe} é‡‡é›†ä»»åŠ¡ (é—´éš”: {config.collection_interval}ç§’)"
                )

        self.logger.info(f"âœ… å·²å¯åŠ¨ {len(self._collection_tasks)} ä¸ªé‡‡é›†ä»»åŠ¡")

    async def stop(self, timeout: float = 5.0) -> None:
        """åœæ­¢æ‰€æœ‰é‡‡é›†ä»»åŠ¡"""
        self.running = False
        self.logger.info("æ­£åœ¨åœæ­¢Kçº¿é‡‡é›†ä»»åŠ¡...")

        # å–æ¶ˆæ‰€æœ‰ä»»åŠ¡
        for task in self._collection_tasks:
            if not task.done():
                task.cancel()

        # ç­‰å¾…ä»»åŠ¡å®Œæˆ
        if self._collection_tasks:
            await asyncio.wait(self._collection_tasks, timeout=timeout)

        self._collection_tasks.clear()
        self.logger.info("âœ… Kçº¿é‡‡é›†ä»»åŠ¡å·²åœæ­¢")

    async def _collection_loop(
        self,
        symbol: str,
        timeframe: str,
        config: TimeframeConfig
    ) -> None:
        """å•ä¸ªæ—¶é—´å‘¨æœŸçš„é‡‡é›†å¾ªç¯"""
        task_key = self._get_task_key(symbol, timeframe)

        try:
            while self.running:
                try:
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡‡é›†
                    last_time = self._last_collection.get(task_key, 0)
                    elapsed = time.time() - last_time

                    if elapsed < config.collection_interval:
                        # è¿˜æœªåˆ°é‡‡é›†æ—¶é—´ï¼Œç­‰å¾…
                        await asyncio.sleep(config.collection_interval - elapsed)
                        continue

                    # æ‰§è¡Œé‡‡é›†
                    await self._collect_and_save(symbol, timeframe, config)

                    # æ›´æ–°æœ€åé‡‡é›†æ—¶é—´
                    self._last_collection[task_key] = time.time()

                except asyncio.CancelledError:
                    break
                except Exception as e:
                    self.logger.error(
                        f"é‡‡é›† {symbol} {timeframe} å¤±è´¥: {e}",
                        exc_info=True
                    )
                    await asyncio.sleep(config.collection_interval)

        except Exception as e:
            self.logger.error(f"é‡‡é›†å¾ªç¯å¼‚å¸¸ {symbol} {timeframe}: {e}")

    async def _collect_and_save(
        self,
        symbol: str,
        timeframe: str,
        config: TimeframeConfig
    ) -> None:
        """é‡‡é›†Kçº¿å¹¶ä¿å­˜åˆ°å„å±‚ç¼“å­˜"""
        try:
            if not hasattr(self, "_latest_timestamp"):
                self._latest_timestamp = {}
            # 1. ä»APIè·å–æœ€æ–°Kçº¿
            cache_key = self._get_cache_key(symbol, timeframe)
            last_ts = self._latest_timestamp.get(cache_key)

            fetch_since = None
            fetch_limit = config.limit
            incremental_attempted = False

            if last_ts:
                fetch_since = int(last_ts + 1)
                fetch_limit = min(getattr(config, "incremental_limit", config.limit), config.limit)
                incremental_attempted = True

            klines = await self.market_collector.get_ohlcv(
                symbol,
                timeframe=timeframe,
                limit=fetch_limit,
                since=fetch_since
            )

            if incremental_attempted and not klines:
                self.logger.debug(
                    "%s %s å¢é‡æ‹‰å–æ— æ•°æ®ï¼Œå›é€€å…¨é‡", symbol, timeframe
                )
                fetch_since = None
                klines = await self.market_collector.get_ohlcv(
                    symbol,
                    timeframe=timeframe,
                    limit=config.limit,
                    since=None
                )

            if not klines:
                self.logger.warning(f"{symbol} {timeframe} æ— å¯ç”¨Kçº¿æ•°æ®")
                return

            # 2. æ›´æ–°å†…å­˜ç¼“å­˜
            cache_key = self._get_cache_key(symbol, timeframe)
            if fetch_since and cache_key in self._memory_cache:
                existing = self._memory_cache[cache_key]["data"]
                existing_ts = {k.timestamp for k in existing}
                merged = existing + [k for k in klines if k.timestamp not in existing_ts]
                merged.sort(key=lambda item: item.timestamp)
                trimmed = merged[-config.limit :]
                cache_data = trimmed
            else:
                cache_data = klines[-config.limit :]

            self._memory_cache[cache_key] = {
                "data": cache_data,
                "timestamp": time.time(),
                "symbol": symbol,
                "timeframe": timeframe,
            }
            self._latest_timestamp[cache_key] = cache_data[-1].timestamp

            # 3. ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆä½¿ç”¨ç‹¬ç«‹sessioné¿å…å¹¶å‘å†²çªï¼‰
            if self.db_manager:
                dao = None
                try:
                    # ä¸ºæ¯æ¬¡ä¿å­˜åˆ›å»ºç‹¬ç«‹çš„DAOå®ä¾‹ï¼ˆå¸¦ç‹¬ç«‹sessionï¼‰
                    dao = await self.db_manager.get_dao()
                    saved_count = await dao.save_klines(
                        symbol=symbol,
                        timeframe=timeframe,
                        klines=klines
                    )
                    # æäº¤äº‹åŠ¡
                    await dao.session.commit()
                    self.logger.debug(
                        f"ä¿å­˜ {symbol} {timeframe} {saved_count} æ ¹Kçº¿åˆ°æ•°æ®åº“"
                    )
                except Exception as db_error:
                    # å›æ»šäº‹åŠ¡
                    if dao and dao.session:
                        await dao.session.rollback()
                    self.logger.warning(
                        f"ä¿å­˜Kçº¿åˆ°æ•°æ®åº“å¤±è´¥ {symbol} {timeframe}: {db_error}"
                    )
                finally:
                    # å…³é—­session
                    if dao and dao.session:
                        await dao.session.close()
            elif self.dao:
                # å‘åå…¼å®¹ï¼šå¦‚æœä¼ å…¥äº†daoï¼Œä½¿ç”¨æ—§æ–¹å¼ï¼ˆä¸æ¨èï¼Œæœ‰å¹¶å‘é—®é¢˜ï¼‰
                try:
                    saved_count = await self.dao.save_klines(
                        symbol=symbol,
                        timeframe=timeframe,
                        klines=klines
                    )
                    await self.dao.session.commit()
                    self.logger.debug(
                        f"ä¿å­˜ {symbol} {timeframe} {saved_count} æ ¹Kçº¿åˆ°æ•°æ®åº“"
                    )
                except Exception as db_error:
                    await self.dao.session.rollback()
                    self.logger.warning(
                        f"ä¿å­˜Kçº¿åˆ°æ•°æ®åº“å¤±è´¥ {symbol} {timeframe}: {db_error}"
                    )

            # 4. å¯é€‰: ä¿å­˜åˆ°Redisï¼ˆç”¨äºè·¨è¿›ç¨‹å…±äº«ï¼‰
            # TODO: å®ç°Redisç¼“å­˜

        except Exception as e:
            self.logger.error(f"é‡‡é›†ä¿å­˜Kçº¿å¤±è´¥ {symbol} {timeframe}: {e}")

    async def get_klines(
        self,
        symbol: str,
        timeframe: str,
        limit: int = 100,
        use_cache: bool = True
    ) -> List[Any]:
        """
        æ™ºèƒ½è·å–Kçº¿æ•°æ®ï¼ˆå¤šå±‚ç¼“å­˜ç­–ç•¥ï¼‰

        ä¼˜å…ˆçº§:
        1. å†…å­˜ç¼“å­˜ï¼ˆæœ€å¿«ï¼‰
        2. Redisç¼“å­˜ï¼ˆæ¬¡å¿«ï¼‰
        3. æ•°æ®åº“ï¼ˆå†å²æ•°æ®ï¼‰
        4. APIå®æ—¶è·å–ï¼ˆå…œåº•ï¼‰

        Args:
            symbol: äº¤æ˜“å¯¹
            timeframe: æ—¶é—´å‘¨æœŸ
            limit: è¿”å›æ•°é‡
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜

        Returns:
            Kçº¿æ•°æ®åˆ—è¡¨
        """
        cache_key = self._get_cache_key(symbol, timeframe)

        # å±‚1: å†…å­˜ç¼“å­˜
        if use_cache and cache_key in self._memory_cache:
            cached = self._memory_cache[cache_key]
            age = time.time() - cached["timestamp"]

            if age < self.strategy.memory_cache_ttl:
                self.logger.debug(
                    f"[å†…å­˜ç¼“å­˜å‘½ä¸­] {symbol} {timeframe} (å¹´é¾„: {age:.1f}ç§’)"
                )
                return cached["data"][:limit]

        # å±‚2: Redisç¼“å­˜
        # TODO: å®ç°Redisç¼“å­˜è¯»å–
        # if use_cache:
        #     redis_data = await self._get_from_redis(symbol, timeframe, limit)
        #     if redis_data:
        #         return redis_data

        # å±‚3: æ•°æ®åº“ï¼ˆä½¿ç”¨ç‹¬ç«‹sessionï¼‰
        if use_cache and self.db_manager:
            dao = None
            try:
                dao = await self.db_manager.get_dao()
                db_klines = await dao.get_klines(
                    symbol=symbol,
                    timeframe=timeframe,
                    limit=limit
                )
                if db_klines:
                    self.logger.debug(
                        f"[æ•°æ®åº“å‘½ä¸­] {symbol} {timeframe} ({len(db_klines)} æ¡)"
                    )
                    # è½¬æ¢ä¸ºOHLCVå¯¹è±¡æ ¼å¼ï¼ˆå¦‚éœ€è¦ï¼‰
                    # TODO: è½¬æ¢æ•°æ®æ ¼å¼
                    return db_klines
            except Exception as e:
                self.logger.warning(f"ä»æ•°æ®åº“è·å–Kçº¿å¤±è´¥: {e}")
            finally:
                if dao and dao.session:
                    await dao.session.close()
        elif use_cache and self.dao:
            # å‘åå…¼å®¹
            try:
                db_klines = await self.dao.get_klines(
                    symbol=symbol,
                    timeframe=timeframe,
                    limit=limit
                )
                if db_klines:
                    self.logger.debug(
                        f"[æ•°æ®åº“å‘½ä¸­] {symbol} {timeframe} ({len(db_klines)} æ¡)"
                    )
                    return db_klines
            except Exception as e:
                self.logger.warning(f"ä»æ•°æ®åº“è·å–Kçº¿å¤±è´¥: {e}")

        # å±‚4: APIå®æ—¶è·å–ï¼ˆå…œåº•ï¼‰
        if self.strategy.enable_api_fallback:
            try:
                self.logger.debug(f"[APIè·å–] {symbol} {timeframe}")
                klines = await self.market_collector.get_ohlcv(
                    symbol,
                    timeframe=timeframe,
                    limit=limit
                )

                # æ›´æ–°å†…å­˜ç¼“å­˜
                if klines:
                    self._memory_cache[cache_key] = {
                        "data": klines,
                        "timestamp": time.time(),
                        "symbol": symbol,
                        "timeframe": timeframe,
                    }

                return klines

            except Exception as e:
                self.logger.error(f"ä»APIè·å–Kçº¿å¤±è´¥: {e}")
                return []

        return []

    async def cleanup_expired_data(self) -> Dict[str, int]:
        """
        æ¸…ç†è¿‡æœŸæ•°æ®ï¼ˆä½¿ç”¨ç‹¬ç«‹sessionï¼‰

        Returns:
            æ¸…ç†ç»Ÿè®¡ {timeframe: deleted_count}
        """
        if not self.db_manager and not self.dao:
            self.logger.warning("æ•°æ®åº“ç®¡ç†å™¨æœªé…ç½®ï¼Œæ— æ³•æ¸…ç†æ•°æ®")
            return {}

        stats = {}
        # ä½¿ç”¨ä¸å¸¦æ—¶åŒºçš„datetimeï¼Œå› ä¸ºæ•°æ®åº“å­—æ®µæ˜¯TIMESTAMP WITHOUT TIME ZONE
        now = datetime.now(timezone.utc).replace(tzinfo=None)
        dao = None

        try:
            # åˆ›å»ºç‹¬ç«‹sessionç”¨äºæ¸…ç†æ“ä½œ
            if self.db_manager:
                dao = await self.db_manager.get_dao()
            else:
                dao = self.dao  # å‘åå…¼å®¹

            async with dao.session.begin():
                for timeframe, config in KLINE_CONFIGS.items():
                    if config.retention_days == 0:
                        # æ°¸ä¹…ä¿ç•™
                        continue

                    # è®¡ç®—è¿‡æœŸæ—¶é—´ï¼ˆä¸å¸¦æ—¶åŒºï¼‰
                    cutoff_date = now - timedelta(days=config.retention_days)

                    # åˆ é™¤è¿‡æœŸæ•°æ®
                    from sqlalchemy import delete
                    from src.database.models import KlineModel

                    result = await dao.session.execute(
                        delete(KlineModel).where(
                            KlineModel.timeframe == timeframe,
                            KlineModel.datetime < cutoff_date
                        )
                    )

                    deleted_count = result.rowcount
                    stats[timeframe] = deleted_count

                    if deleted_count > 0:
                        self.logger.info(
                            f"æ¸…ç† {timeframe} è¿‡æœŸæ•°æ®: {deleted_count} æ¡ "
                            f"(æ—©äº {cutoff_date.date()})"
                        )

            return stats

        except Exception as e:
            self.logger.error(f"æ¸…ç†è¿‡æœŸæ•°æ®å¤±è´¥: {e}")
            return stats
        finally:
            # å¦‚æœæ˜¯æ–°åˆ›å»ºçš„sessionï¼Œéœ€è¦å…³é—­
            if dao and dao is not self.dao and dao.session:
                await dao.session.close()

    def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            "memory_cache_size": len(self._memory_cache),
            "active_tasks": len([t for t in self._collection_tasks if not t.done()]),
            "timeframes": {},
        }

        # æŒ‰æ—¶é—´å‘¨æœŸç»Ÿè®¡
        for cache_key, cached in self._memory_cache.items():
            tf = cached.get("timeframe")
            if tf not in stats["timeframes"]:
                stats["timeframes"][tf] = {
                    "count": 0,
                    "total_klines": 0,
                    "avg_age": 0,
                }

            stats["timeframes"][tf]["count"] += 1
            stats["timeframes"][tf]["total_klines"] += len(cached["data"])
            stats["timeframes"][tf]["avg_age"] += time.time() - cached["timestamp"]

        # è®¡ç®—å¹³å‡å€¼
        for tf_stats in stats["timeframes"].values():
            if tf_stats["count"] > 0:
                tf_stats["avg_age"] /= tf_stats["count"]

        return stats
        self._latest_timestamp: Dict[str, int] = {}
